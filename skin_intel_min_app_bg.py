import io, os, time, json, base64, re
from pathlib import Path
from typing import List
import numpy as np
import pandas as pd
from PIL import Image
import requests

import torch
import torch.nn as nn
from torchvision import models, transforms, datasets

import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st

# ======== CONSTANTS (edit here if –ø—É—Ç–∏ –¥—Ä—É–≥–∏–µ) ========
# Background image (applies to all pages)
BG_IMAGE_PATH   = "/Users/maratalekberov/Desktop/–°–∫—Ä–∏–Ω—ã/Screenshot 2025-09-12 at 17.30.48.png"

# Skin (ResNet50, 2 classes)
SKIN_CKPT_PATH  = "/Users/maratalekberov/Downloads/true.pth"
SKIN_CLASSES    = ["benign", "malignant"]
SKIN_VAL_DIR    = ""  # e.g. "data/skin/val"

# Intel (ResNet18, 6 classes)
INTEL_CKPT_PATH = "resnet18_full_model1.pth"
INTEL_CLASSES   = ["buildings","forest","glacier","mountain","sea","street"]
INTEL_VAL_DIR   = ""  # e.g. "/Users/.../archive/seg_test/seg_test"

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD  = [0.229, 0.224, 0.225]


# ======== STYLES ========
def inject_background(image_path: str):
    p = Path(image_path)
    if not p.is_file():
        return
    data = p.read_bytes()
    b64  = base64.b64encode(data).decode()
    st.markdown(f"""
    <style>
    .stApp {{
        background: url("data:image/png;base64,{b64}") no-repeat center center fixed;
        background-size: cover;
    }}
    .block-container {{
        background: rgba(0,0,0,0.35);
        border-radius: 16px;
        padding: 1.2rem 1.2rem 2rem 1.2rem;
    }}
    section[data-testid="stSidebar"] > div:first-child {{
        background: rgba(0,0,0,0.35);
    }}
    </style>
    """, unsafe_allow_html=True)


# ======== UTILS ========
def get_device():
    if torch.cuda.is_available():
        return torch.device("cuda")
    if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available():
        return torch.device("mps")
    return torch.device("cpu")

def tfm(size=224):
    from torchvision import transforms as T
    return T.Compose([
        T.Resize((size, size)),
        T.ToTensor(),
        T.Normalize(IMAGENET_MEAN, IMAGENET_STD),
    ])

def load_image_from_url(url: str) -> Image.Image:
    r = requests.get(url, timeout=20)
    r.raise_for_status()
    return Image.open(io.BytesIO(r.content)).convert("RGB")

def _strip_prefix(sd, prefix):
    return {k[len(prefix):] if k.startswith(prefix) else k: v for k, v in sd.items()}

def detect_resnet_arch(sd: dict) -> str:
    w = sd.get("layer1.0.conv1.weight")
    if w is not None and w.ndim == 4:
        kH, kW = w.shape[2], w.shape[3]
        if kH == 3 and kW == 3:  # basic block
            return "resnet18"
        if kH == 1 and kW == 1:  # bottleneck
            return "resnet50"
    fcw = sd.get("fc.weight")
    if fcw is not None and fcw.ndim == 2:
        in_f = fcw.shape[1]
        if in_f == 512:  return "resnet18"
        if in_f == 2048: return "resnet50"
    return "resnet18"

def load_model_resnet(ckpt_path: str, target_arch: str, out_dim: int, device):
    if not Path(ckpt_path).is_file():
        raise FileNotFoundError(f"Checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω: {ckpt_path}")
    obj = torch.load(ckpt_path, map_location="cpu", weights_only=False)
    if isinstance(obj, dict) and "state_dict" in obj:
        sd = obj["state_dict"]
    elif isinstance(obj, dict):
        sd = obj
    elif hasattr(obj, "state_dict"):
        sd = obj.state_dict()
    else:
        raise RuntimeError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —á–µ–∫–ø–æ–∏–Ω—Ç–∞")

    for pref in ("module.", "model."):
        if any(k.startswith(pref) for k in sd):
            sd = _strip_prefix(sd, pref)

    arch_by_sd = detect_resnet_arch(sd)
    arch = target_arch or arch_by_sd

    if arch == "resnet50":
        net = models.resnet50(weights=None)
    else:
        net = models.resnet18(weights=None)

    net.fc = nn.Linear(net.fc.in_features, out_dim)
    net.load_state_dict(sd, strict=False)
    net.to(device).eval()
    return net

def extract_all_markdown(file_path: Path) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π Markdown –∏–∑ —Ñ–∞–π–ª–∞:
    - –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä–∏ —Ç—Ä–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫ (—Ç—Ä–∏ –¥–≤–æ–π–Ω—ã–µ –∏–ª–∏ —Ç—Ä–∏ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ)
    - –µ—Å–ª–∏ —Ç–∞–∫–∏—Ö –±–ª–æ–∫–æ–≤ –Ω–µ—Ç, –∏—â–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–∏–¥–∞ text, text1, text2 —Å –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–º–∏/–æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
    - –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–∞
    """
    if not file_path.is_file():
        return ""
    raw = file_path.read_text(encoding="utf-8", errors="ignore")

    blocks = []
    # —Ç—Ä–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
    for pat in (r'"""(.*?)"""', r"'''(.*?)'''"):
        blocks += re.findall(pat, raw, flags=re.DOTALL)
    if blocks:
        return "\n\n".join(b.strip() for b in blocks if b.strip())

    # –ø–æ–ø—ã—Ç–∫–∞ –≤—ã—Ç–∞—â–∏—Ç—å text/text1/text2/... = """...""" –∏–ª–∏ '...'
    for var in ("text", "text1", "text2", "text3"):
        m = re.search(var + r"\s*=\s*(?:[urUR]?)(['\"]{3})(.*?)\1", raw, flags=re.DOTALL)
        if m:
            return m.group(2).strip()
        m = re.search(var + r"\s*=\s*(['\"])(.*?)\1", raw, flags=re.DOTALL)
        if m:
            return m.group(2).strip()

    # –∏–Ω–∞—á–µ ‚Äî –≤–µ—Å—å —Å—ã—Ä–æ–π —Ñ–∞–π–ª
    return raw.strip()


# ======== PAGES ========
def page_home():
    st.title("COMETS-2025")
    st.subheader("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: Skin disease and Landscape")
    st.markdown("‚Äî")
    st.markdown("### üë• –£—á–∞—Å—Ç–Ω–∏–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("- **–ù–∞–¥–µ–∂–¥–∞ –ò—à–ø–∞–π–∫–∏–Ω–∞**\n- **–î–º–∏—Ç—Ä–∏–π –ö–æ—à–µ–ª–µ–≤**")
    with col2:
        st.markdown("- **–Ø—Ä–æ—Å–ª–∞–≤ –ü–∞—Ö–æ–º–æ–≤**\n- **–ú–∞—Ä–∞—Ç –ê–ª–µ–∫–±–µ—Ä–æ–≤**")
    st.divider()
    st.markdown(
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é —Å–ª–µ–≤–∞, —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã **Skin Disease** (ResNet50), "
        "**Landscape** (ResNet18) –∏–ª–∏ **üìä –û—Ç—á—ë—Ç –∏ –º–µ—Ç—Ä–∏–∫–∏**."
    )

def page_skin():
    st.header("ü©∫ Skin disease")
    device = get_device()
    st.caption(f"Device: **{device.type}**")

    try:
        model = load_model_resnet(SKIN_CKPT_PATH, target_arch="resnet50", out_dim=len(SKIN_CLASSES), device=device)
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
        return

    size = st.slider("Input size", 160, 512, 224, 16)
    # –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –ø—Ä–µ–≤—å—é: —Å–ª–∞–π–¥–µ—Ä —à–∏—Ä–∏–Ω—ã
    thumb_w = st.slider("–†–∞–∑–º–µ—Ä –ø—Ä–µ–≤—å—é, px", 96, 512, 220, 8, key="thumb_w_skin")

    c1, c2 = st.columns(2)
    with c1:
        files = st.file_uploader("Upload images", type=["jpg","jpeg","png","bmp","webp","tif","tiff"], accept_multiple_files=True)
    with c2:
        urls_text = st.text_area("Or paste URLs (one per line)")

    if st.button("Classify", type="primary"):
        imgs: List[Image.Image] = []
        names: List[str] = []
        for f in files or []:
            try:
                imgs.append(Image.open(f).convert("RGB"))
                names.append(f.name)
            except Exception as e:
                st.warning(f"{f.name}: {e}")
        for line in (urls_text or "").splitlines():
            u = line.strip()
            if not u:
                continue
            try:
                imgs.append(load_image_from_url(u))
                names.append(Path(u).name)
            except Exception as e:
                st.warning(f"{u}: {e}")
        if not imgs:
            st.info("–î–æ–±–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ URL.")
            return

        xb = torch.stack([tfm(size)(im) for im in imgs]).to(device)
        t0 = time.perf_counter()
        with torch.inference_mode():
            logits = model(xb)
            probs = torch.softmax(logits, dim=1).cpu().numpy()
        elapsed = time.perf_counter() - t0
        st.success(f"‚è± Processing time: {elapsed:.3f}s  (~{elapsed/len(imgs):.4f}s/img)")

        pred_idx = probs.argmax(axis=1)
        rows = [{"image": n, "pred": SKIN_CLASSES[p], "confidence": float(probs[i, p])}
                for i, (n, p) in enumerate(zip(names, pred_idx))]
        st.dataframe(pd.DataFrame(rows), use_container_width=True)

        cols = st.columns(min(5, len(imgs)))
        for i, (im, n) in enumerate(zip(imgs, names)):
            label = SKIN_CLASSES[pred_idx[i]]
            with cols[i % len(cols)]:
                st.image(im, caption=f"{n} ‚Üí {label} ({probs[i, pred_idx[i]]:.2%})", width=thumb_w)

def page_intel():
    st.header("üåç Landscape")
    device = get_device()
    st.caption(f"Device: **{device.type}**")

    try:
        model = load_model_resnet(INTEL_CKPT_PATH, target_arch="resnet18", out_dim=len(INTEL_CLASSES), device=device)
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
        return

    size = st.slider("Input size", 160, 512, 224, 16, key="intel_size")
    # –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –ø—Ä–µ–≤—å—é: —Å–ª–∞–π–¥–µ—Ä —à–∏—Ä–∏–Ω—ã
    thumb_w = st.slider("–†–∞–∑–º–µ—Ä –ø—Ä–µ–≤—å—é, px", 96, 512, 220, 8, key="thumb_w_intel")

    c1, c2 = st.columns(2)
    with c1:
        files = st.file_uploader("Upload images (multi)", type=["jpg","jpeg","png","bmp","webp","tif","tiff"], accept_multiple_files=True, key="intel_files")
    with c2:
        urls_text = st.text_area("Or paste URLs (one per line)", key="intel_urls")

    if st.button("Classify", type="primary", key="intel_run"):
        imgs: List[Image.Image] = []
        names: List[str] = []
        for f in files or []:
            try:
                imgs.append(Image.open(f).convert("RGB"))
                names.append(f.name)
            except Exception as e:
                st.warning(f"{f.name}: {e}")
        for line in (urls_text or "").splitlines():
            u = line.strip()
            if not u:
                continue
            try:
                imgs.append(load_image_from_url(u))
                names.append(Path(u).name)
            except Exception as e:
                st.warning(f"{u}: {e}")
        if not imgs:
            st.info("–î–æ–±–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ URL.")
            return

        xb = torch.stack([tfm(size)(im) for im in imgs]).to(device)
        t0 = time.perf_counter()
        with torch.inference_mode():
            logits = model(xb)
            probs = torch.softmax(logits, dim=1).cpu().numpy()
        elapsed = time.perf_counter() - t0
        st.success(f"‚è± Processing time: {elapsed:.3f}s  (~{elapsed/len(imgs):.4f}s/img)")

        pred_idx = probs.argmax(axis=1)
        rows = [{"image": n, "pred": INTEL_CLASSES[p], "confidence": float(probs[i, p])}
                for i, (n, p) in enumerate(zip(names, pred_idx))]
        st.dataframe(pd.DataFrame(rows), use_container_width=True)

        cols = st.columns(min(5, len(imgs)))
        for i, (im, n) in enumerate(zip(imgs, names)):
            label = INTEL_CLASSES[pred_idx[i]]
            with cols[i % len(cols)]:
                st.image(im, caption=f"{n} ‚Üí {label} ({probs[i, pred_idx[i]]:.2%})", width=thumb_w)

def page_report():
    st.header("üìä –û—Ç—á—ë—Ç –∏ –º–µ—Ç—Ä–∏–∫–∏")

    base = Path(__file__).resolve().parent

    # 1) –¢–ï–ö–°–¢: –ø–æ–¥—Ç—è–Ω—É—Ç—å –í–°–Å –∏–∑ main.py –∏ main1.py
    text_blocks_found = False
    for name in ("main.py", "main1.py"):
        p = base / name
        md = extract_all_markdown(p)
        if md:
            text_blocks_found = True
            st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{name}`")
            st.markdown(md)
            st.markdown("---")
    if not text_blocks_found:
        st.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ –≤ main.py / main1.py. –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ —Ñ–∞–π–ª—ã –ª–µ–∂–∞—Ç —Ä—è–¥–æ–º –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç Markdown –≤ —Ç—Ä–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö.")

    # 2) –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –ú–ï–¢–†–ò–ö: –ø–æ–∫–∞–∂–µ–º –≤—Å—ë, —á—Ç–æ –µ—Å—Ç—å (1 –∏ 2)
    img_sets = [
        ("Metrics1.png", "Heatmap1.png", "–ú–æ–¥–µ–ª—å / –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 1"),
        ("Metrics2.png", "Heatmap2.png", "–ú–æ–¥–µ–ª—å / –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 2"),
    ]
    for m_img, h_img, title in img_sets:
        m_path = base / m_img
        h_path = base / h_img
        if m_path.exists() or h_path.exists():
            st.subheader(title)
            cols = st.columns(2)
            with cols[0]:
                if m_path.exists():
                    st.image(str(m_path), use_container_width=True, caption=f"{m_img} ‚Äî –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è/–º–µ—Ç—Ä–∏–∫")
                else:
                    st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {m_path}")
            with cols[1]:
                if h_path.exists():
                    st.image(str(h_path), use_container_width=True, caption=f"{h_img} ‚Äî Confusion Matrix (heatmap)")
                else:
                    st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {h_path}")
            st.markdown("---")

    # 3) –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è .png –≤ –ø–∞–ø–∫–µ
    known = {n for pair in img_sets for n in pair[:2]}
    extras = [p for p in base.glob("*.png") if p.name not in known]
    if extras:
        st.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        for p in extras:
            st.image(str(p), use_container_width=True, caption=p.name)


# ======== MAIN ========
st.set_page_config(page_title="Skin & Intel Classifiers ‚Äî Minimal (BG)", layout="wide")
inject_background(BG_IMAGE_PATH)

page = st.sidebar.radio("Page", ["üè† Title", "Skin Disease", "Landscape", "üìä –û—Ç—á—ë—Ç –∏ –º–µ—Ç—Ä–∏–∫–∏"], index=0)

if page == "üè† Title":
    page_home()
elif page == "Skin Disease":
    page_skin()
elif page == "Landscape":
    page_intel()
else:
    page_report()
